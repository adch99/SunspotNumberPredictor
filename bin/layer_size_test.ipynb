{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/aditya/Documents/SolarCycleProject/code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import gaussian\n",
    "import src.preprocesser as pre\n",
    "import src.network as network\n",
    "import src.plotter as plotter \n",
    "from src.hyperparams import *\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data\n",
    "headers = [\"Year\",\n",
    "           \"Month\",\n",
    "           \"Day\",\n",
    "           \"Decimal Date\",\n",
    "           \"Daily Total Sunspot Number\",\n",
    "           \"Sunspot Number Stddev\",\n",
    "           \"No of observations\",\n",
    "           \"Definitive/Provisional\"\n",
    "]\n",
    "filename = \"data/SN_d_tot_V2.0.csv\"\n",
    "data = pd.read_csv(filename, delimiter=\";\", names=headers)[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "dates, spots, inverter = pre.preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mean_type == \"gaussian\":\n",
    "    weights = gaussian(M=mean_length, std=0.1, sym=True)\n",
    "    weights /= np.sum(weights) # normalise the weights\n",
    "    spots = pre.running_mean_helper(spots, weights)\n",
    "elif mean_type == \"uniform\":\n",
    "    weights = np.ones(mean_length)/mean_length\n",
    "    spots = pre.running_mean_helper(spots, weights)\n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spots\n",
    "index = dates\n",
    "x_slid, y_slid, idx_slid = pre.sliding_window_main(X, X, index)\n",
    "x_train, y_train, idx_train, x_val, y_val, idx_val, x_test, y_test, idx_test = pre.data_splitting_main(x_slid, y_slid, idx_slid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlayer_sizes = np.arange(1, 101, 1)\n",
    "nets = []\n",
    "for layer_size in hlayer_sizes:\n",
    "    net = network.create_network(layer_size=layer_size)\n",
    "    nets.append(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []\n",
    "losses = []\n",
    "val_losses = []\n",
    "for i in range(len(hlayer_sizes)):\n",
    "    net = nets[i]\n",
    "    print(\"Training network with hidden layer size:\", hlayer_sizes[i])\n",
    "    history = network.trainer(net, x_train, y_train, x_val, y_val, verbose=0)\n",
    "    loss = history.history[\"loss\"][-1]\n",
    "    losses.append(loss)\n",
    "    val_loss = history.history[\"val_loss\"][-1]\n",
    "    val_losses.append(val_loss)\n",
    "    print(\"epochs: %d - loss: %.4f - val_loss: %.4f\" % (epochs, loss, val_loss))\n",
    "    print(\"Training Completed\")\n",
    "    print()\n",
    "    histories.append(history)\n",
    "    \n",
    "var_train = np.var(y_train)\n",
    "var_val = np.var(y_val)\n",
    "print(\"Variance in y_train:\", var_train)\n",
    "print(\"Variance in y_val:\", var_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(hlayer_sizes)):\n",
    "    net = nets[i]\n",
    "    history = histories[i]\n",
    "    plotter.plot_predictions(net, x_train, y_train, idx_train, x_val, y_val, idx_val)\n",
    "    plt.close()\n",
    "    plotter.plot_loss_vs_epoch(history, var_train, var_val, show=False)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hlayer_sizes, losses, label=\"Training Loss\", marker=\"o\")\n",
    "plt.plot(hlayer_sizes, val_losses, label=\"Validation Loss\", marker=\"o\")\n",
    "plt.xlabel(\"Hidden Layer Size\")\n",
    "plt.ylabel(\"Mean Square Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"img/loss_vs_layersize.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
